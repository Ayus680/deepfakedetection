{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beefd3b-4136-4391-a0ce-5c45187782d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50c6308b-f4f6-4228-8ab0-62c071800961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - accuracy: 0.5000 - loss: 1.1854\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "['.ai-navigator', '.anaconda', '.cache', '.conda', '.condarc', '.continuum', '.dbus-keyrings', '.deepface', '.gitconfig', '.ipynb_checkpoints', '.ipython', '.jupyter', '.keras', '.matplotlib', '.ms-ad', '.nbi', '.node_repl_history', '.packettracer', '.virtual_documents', '.vscode', '2107_ayushkumar (1).ipynb', '22052107 - Shortcut.lnk', 'AccountBalance.java', 'AD.java', 'adlab1 (1).ipynb', 'adlab1.ipynb', 'ADLAB1ASSIGNMENT.ipynb', 'anaconda3', 'AppData', 'Application Data', 'Autodesk Desktop App.lnk', 'backtracking .ipynb', 'Bahubali2vsDangal.csv', 'Balitmore_salry.csv', 'bfs.ipynb', 'Bolywood_ML.ipynb', 'breastcancerml.ipynb', 'Breast_Cancer_Detection_Using_Machine_Learning_Classifier (1).ipynb', 'breast_cancer_raw.csv', 'c', 'c.c', 'c.exe', 'Calculator.java', 'company_sales_data.csv', 'company_sales_data.xlsx', 'Contacts', 'Cookies', 'Credit_ML.ipynb', 'data.bin', 'data.txt', 'dataset.zip', 'Deep GAN.ipynb', 'deepfakedetection.ipynb', 'deepfakee.py', 'deepfake_detector.keras', 'Desktop', 'dictionaryaslabday2.ipynb', 'directory to extract', 'Documents', 'download.jpg', 'Downloads', 'example.txt', 'fake_1.jpg', 'Favorites', 'Foodtruck.csv', 'g', 'horse-human.ipynb', 'HrsException.class', 'IdeaProjects', 'informationgatheringagent.ipynb', 'IntelGraphicsProfiles', 'lab', 'lab2.ipynb', 'labprogrammingtest.ipynb', 'linear_regression.ipynb', 'Links', 'listadlab2.ipynb', 'Local Settings', 'Main.java', 'MATPLOTLIB.ipynb', 'micromamba', 'minconflict.ipynb', 'minconflicts(mapcoloring).ipynb', 'MinException.class', 'MINIMUM CONFLICTS AI.ipynb', 'minimum conflicts(mapColoring).ipynb', 'minimumconflicts.ipynb', 'minor.ipynb', 'ml.ipynb', 'mlproject1.ipynb', 'ml_1.ipynb', 'Music', 'My Documents', 'NetHood', 'new code', 'New folder', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{58de9112-bdcb-11ed-9f27-010101010000}.TM.blf', 'NTUSER.DAT{58de9112-bdcb-11ed-9f27-010101010000}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{58de9112-bdcb-11ed-9f27-010101010000}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'numpy.ipynb', 'NUMPY1.ipynb', 'OneDrive', 'Oracle', 'os', 'oslab', 'penguins_size.csv', 'Pictures', 'Postman', 'PrintHood', 'pythonbasics.ipynb', 'pythonml.java', 'q1.java', 'Rainfall.csv', 'real_1.jpg', 'real_img.jpg', 'Recent', 's.c', 's.exe', 'Salaries (1).csv', 'Salaries.csv', 'Salary_Data.csv', 'Saved Games', 'Searches', 'SecException.class', 'SendTo', 'Shopping_CustomerData.csv', 'Simpl.java', 'Start Menu', 'StudentPerformanceFactors.csv', 'SUNRISE.jpg', 'SUNSET.jpg', 'Templates', 'test1.ipynb', 'Time.class', 'Untitled-1.c', 'Untitled-1.exe', 'Untitled-1.html', 'Untitled-1.java', 'Untitled-1.py', 'Untitled-2.c', 'Untitled-2.html', 'Untitled.ipynb', 'Untitled1.ipynb', 'Untitled10.ipynb', 'Untitled11.ipynb', 'Untitled12.ipynb', 'Untitled13.ipynb', 'Untitled14.ipynb', 'Untitled15.ipynb', 'Untitled16.ipynb', 'Untitled17.ipynb', 'Untitled18.ipynb', 'Untitled19.ipynb', 'Untitled2.ipynb', 'Untitled20.ipynb', 'Untitled21.ipynb', 'Untitled22.ipynb', 'Untitled23.ipynb', 'Untitled24.ipynb', 'Untitled25.ipynb', 'Untitled26.ipynb', 'Untitled27.ipynb', 'Untitled28.ipynb', 'Untitled29.ipynb', 'Untitled3.ipynb', 'Untitled30.ipynb', 'Untitled31.ipynb', 'Untitled32.ipynb', 'Untitled33.ipynb', 'Untitled34.ipynb', 'Untitled35.ipynb', 'Untitled36.ipynb', 'Untitled37.ipynb', 'Untitled38.ipynb', 'Untitled39.ipynb', 'Untitled4.ipynb', 'Untitled40.ipynb', 'Untitled41.ipynb', 'Untitled42.ipynb', 'Untitled43.ipynb', 'Untitled44.ipynb', 'Untitled5.ipynb', 'Untitled6.ipynb', 'Untitled7.ipynb', 'Untitled8.ipynb', 'Untitled9.ipynb', 'Videos', 'WPS Cloud Files']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Datasets/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 81\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir())  \u001b[38;5;66;03m# Shows all files and folders in the current directory\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# In[25]:\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasets/\u001b[39m\u001b[38;5;124m\"\u001b[39m))        \u001b[38;5;66;03m# Should show ['Train', 'Validation', 'Test']\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasets/Train/\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# Should show ['real', 'fake']\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasets/Validation/\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# Should show ['real', 'fake']\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Datasets/'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load pre-trained ResNet50 model without the top layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load images\n",
    "real_img_path = 'real_1.jpg'\n",
    "fake_img_path = 'fake_1.jpg'\n",
    "\n",
    "def load_and_preprocess(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "# Prepare dataset\n",
    "real_img = load_and_preprocess(real_img_path)\n",
    "fake_img = load_and_preprocess(fake_img_path)\n",
    "X_train = np.vstack([real_img, fake_img])\n",
    "y_train = np.array([0, 1])  # 0 for real, 1 for fake\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=2)\n",
    "\n",
    "# Save the model\n",
    "model.save('deepfake_detector.keras')\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "import zipfile as zf\n",
    "files = zf.ZipFile(\"Dataset.zip\", 'r')\n",
    "files.extractall('directory to extract')\n",
    "files.close()\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir())  # Shows all files and folders in the current directory\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "print(os.listdir(\"Datasets/\"))        # Should show ['Train', 'Validation', 'Test']\n",
    "print(os.listdir(\"Datasets/Train/\"))  # Should show ['real', 'fake']\n",
    "print(os.listdir(\"Datasets/Validation/\"))  # Should show ['real', 'fake']\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "# Define image size and batch size\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Data Preprocessing\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load Training Data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'Datasets/Train/', target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Load Validation Data\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    'Datasets/Validation/', target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Print class labels\n",
    "print(\"Class labels:\", train_generator.class_indices)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Load Pretrained ResNet50 Model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze base layers (to use pre-trained features)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  \n",
    "\n",
    "# Add Custom Layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)  # Binary Classification (Real/Fake)\n",
    "\n",
    "# Define Model\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train Model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
    "\n",
    "# Save Model\n",
    "model.save('deepfake_detector.h5')\n",
    "print(\"Model saved as deepfake_detector.h5\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db09b69b-11be-4819-82a3-c90b541fa06c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'deepfake_detector.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load trained model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeepfake_detector.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Function to load and preprocess image\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_preprocess\u001b[39m(img_path):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:196\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    190\u001b[0m         filepath,\n\u001b[0;32m    191\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    193\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    194\u001b[0m     )\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:116\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    114\u001b[0m opened_new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[1;32m--> 116\u001b[0m     f \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(filepath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     f \u001b[38;5;241m=\u001b[39m filepath\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'deepfake_detector.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load trained model\n",
    "model = load_model('deepfake_detector.h5')\n",
    "\n",
    "# Function to load and preprocess image\n",
    "def load_and_preprocess(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))  # Resize to match model input\n",
    "    img_array = image.img_to_array(img)                     # Convert to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)           # Add batch dimension\n",
    "    img_array = preprocess_input(img_array)                 # Preprocess as per ResNet50\n",
    "    return img_array\n",
    "\n",
    "# Load your images\n",
    "real_img = load_and_preprocess('real_1.jpg')\n",
    "fake_img = load_and_preprocess('fake_1.jpg')\n",
    "\n",
    "# Stack into one array\n",
    "X_test = np.vstack([real_img, fake_img])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to class labels (0: Real, 1: Fake)\n",
    "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# Print results\n",
    "label_map = {0: \"Real\", 1: \"Fake\"}\n",
    "for i, pred in enumerate(predicted_labels):\n",
    "    confidence = predictions[i][0]\n",
    "    print(f\"Image {i+1} predicted as: {label_map[pred]} (Confidence: {confidence:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2a8ee-d052-4312-ae9e-6bbab79b996a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
